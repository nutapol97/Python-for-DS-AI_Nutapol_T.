{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification - Gradient Boosting.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqPFbiZJ5/YVfTlP6xbhBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nutapol97/Python-for-DS-AI_Nutapol_T./blob/main/Classification_Gradient_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaqRRkvVKT7b"
      },
      "source": [
        "from scipy.special import expit\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "def train_test(X,Y,size):\n",
        "  from numpy.random import default_rng\n",
        "  import math\n",
        "  rng = default_rng()\n",
        "  SizeTrain=math.ceil((size*X.shape[0]))\n",
        "  random_np=rng.choice(X.shape[0], size=SizeTrain, replace=False)\n",
        "  X_test=X[random_np,:]\n",
        "  y_test=Y[random_np,]\n",
        "  Y_train=np.delete(Y, random_np,axis=0)\n",
        "  X_train=np.delete(X, random_np,axis=0)\n",
        "  Y_train=Y_train.reshape(Y_train.shape[0],)\n",
        "  y_test=y_test.reshape(y_test.shape[0],)\n",
        "  return X_train,X_test,Y_train,y_test\n",
        "class GradientBoosting:\n",
        "    def __init__(self, S=5, alfa=1, max_depth = 1, \n",
        "                 min_samples_split = 2,\n",
        "                 regression=True, tol=1e-4):\n",
        "        self.S = S\n",
        "        self.alfa = alfa\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.regression=regression\n",
        "\n",
        "    def grad(self, y, h):\n",
        "        return y - h\n",
        "    def predict(self, X, models=None, with_argmax=True):\n",
        "        if models is None:\n",
        "            models = self.models\n",
        "        h0 = models[0].predict(X) \n",
        "        boosting = sum(self.alfa * model.predict(X) for model in models[1:])\n",
        "        yhat = h0 + boosting\n",
        "        if not self.regression:\n",
        "            yhat = np.exp(yhat) / np.sum(np.exp(yhat), axis=1, keepdims=True)\n",
        "            if with_argmax:\n",
        "                yhat = np.argmax(yhat, axis=1)\n",
        "        return yhat\n",
        "    def fit(self, X, y):  \n",
        "        tree_params = {'max_depth': self.max_depth,\n",
        "                      'min_samples_split': self.min_samples_split}\n",
        "        self.models = [DecisionTreeRegressor(**tree_params) for _ in range(self.S)]        \n",
        "        first_model = DummyRegressor(strategy='mean')\n",
        "        self.models.insert(0, first_model)\n",
        "        self.models[0].fit(X, y)\n",
        "        \n",
        "        for i in range(self.S):\n",
        "            yhat = self.predict(X, self.models[:i+1], with_argmax=False)\n",
        "            gradient = self.grad(y, yhat)\n",
        "            self.models[i+1].fit(X, gradient)\n",
        "    \n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzXTK5MlKVuE",
        "outputId": "4b81f620-e5fc-4c05-8797-e430394f3509"
      },
      "source": [
        "# Regression\n",
        "X_boston, y_boston = load_boston(return_X_y=True)\n",
        "X_train_boston, X_test_boston, y_train_boston, y_test_boston = train_test(X_boston, y_boston, \n",
        "                        size=0.3)\n",
        "\n",
        "model = GradientBoosting(S=200, alfa=0.1, max_depth = 3, \n",
        "                 min_samples_split = 2,\n",
        "                 regression=True, tol=1e-4)\n",
        "model.fit(X_train_boston, y_train_boston)\n",
        "yhat = model.predict(X_test_boston)\n",
        "print(\"MSE: \", mean_squared_error(y_test_boston, yhat))\n",
        "sklearn_model = GradientBoostingRegressor(n_estimators=200,learning_rate = 0.1,max_depth=3,loss='ls')\n",
        "yhat_sk = sklearn_model.fit(X_train_boston, y_train_boston).predict(X_test_boston)\n",
        "print(\"Sklearn MSE: \", mean_squared_error(y_test_boston, yhat_sk))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  11.343807038149848\n",
            "Sklearn MSE:  11.240423611089325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv9YvbXYKXG2",
        "outputId": "9c0ac7ed-16dc-457d-d344-fbcf79b747fb"
      },
      "source": [
        "# Binary classification\n",
        "X_cancer, y_cancer = load_breast_cancer(return_X_y=True)\n",
        "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test(X_cancer, y_cancer, size=0.3)\n",
        "y_train_cancer_encoded = np.zeros((y_train_cancer.shape[0], len(set(y_cancer))))\n",
        "for each_class in range(len(set(y_cancer))):\n",
        "    cond = y_train_cancer==each_class\n",
        "    y_train_cancer_encoded[np.where(cond), each_class] = 1\n",
        "\n",
        "model = GradientBoosting(S=200, alfa=0.1, max_depth = 3, min_samples_split = 2,regression=False)\n",
        "model.fit(X_train_cancer, y_train_cancer_encoded)\n",
        "yhat_cancer = model.predict(X_test_cancer)\n",
        "\n",
        "print(\"Our accuracy: \", accuracy_score(y_test_cancer, yhat_cancer))\n",
        "\n",
        "sklearn_model = GradientBoostingClassifier(n_estimators=200,learning_rate = 0.1,max_depth=1)\n",
        "yhat_sk = sklearn_model.fit(X_train_cancer, y_train_cancer).predict(X_test_cancer)\n",
        "print(\"Sklearn accuracy: \", accuracy_score(y_test_cancer, yhat_sk))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our accuracy:  0.9298245614035088\n",
            "Sklearn accuracy:  0.9532163742690059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSE3yO89KZLV",
        "outputId": "e0172ad8-ce5b-4f32-b988-0ce23fad7935"
      },
      "source": [
        "# Multiclass classification\n",
        "X_digits, y_digits = load_digits(return_X_y=True)\n",
        "X_train_digits, X_test_digits, y_train_digits, y_test_digits = train_test(X_digits, y_digits, size=0.3)\n",
        "y_train_digits_encoded = np.zeros((y_train_digits.shape[0], len(set(y_digits))))\n",
        "for each_class in range(len(set(y_digits))):\n",
        "    cond = y_train_digits==each_class\n",
        "    y_train_digits_encoded[np.where(cond), each_class] = 1\n",
        "model = GradientBoosting(S=200, alfa=0.1, max_depth = 3,min_samples_split = 2,regression=False)\n",
        "model.fit(X_train_digits, y_train_digits_encoded)\n",
        "yhat = model.predict(X_test_digits)\n",
        "print(\"Our accuracy: \", accuracy_score(y_test_digits, yhat))\n",
        "sklearn_model = GradientBoostingClassifier(n_estimators=200,learning_rate = 0.1,max_depth=1)\n",
        "yhat_sk = sklearn_model.fit(X_train_digits, y_train_digits).predict(X_test_digits)\n",
        "print(\"Sklearn accuracy: \", accuracy_score(y_test_digits, yhat_sk))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our accuracy:  0.9296296296296296\n",
            "Sklearn accuracy:  0.9537037037037037\n"
          ]
        }
      ]
    }
  ]
}